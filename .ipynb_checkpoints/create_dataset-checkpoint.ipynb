{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13462f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "DATA_DIR = './data/'\n",
    "\n",
    "\n",
    "num_samples_per_class = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba371f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mask_utils import *\n",
    "from utils.visualization_utils import *\n",
    "from utils.transform_utils import *\n",
    "from utils.data_utils import * \n",
    "from utils.augmentation_utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e6132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# JSON file\n",
    "f = open (DATA_DIR + './annotations_trainval2017/annotations/instances_val2017.json', \"r\")\n",
    " \n",
    "# Reading from file\n",
    "data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bd81066",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = {1 : 'person',\n",
    "                 3 : 'vehicle',\n",
    "                 4 : 'vehicle',\n",
    "                 6 : 'vehicle',\n",
    "                 8 : 'vehicle',\n",
    "                 18 : 'animal',\n",
    "                 19 : 'animal',\n",
    "                 20 : 'animal',\n",
    "                 21 : 'animal',\n",
    "                 23 : 'animal',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3063e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15310\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "data_useful =[]\n",
    "for ann in data['annotations']:\n",
    "    \n",
    "    if ann['category_id'] in category_dict:\n",
    "        \n",
    "        data_useful.append(ann)\n",
    "\n",
    "print(len(data_useful))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334d4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_category_object(category,\n",
    "                             data_useful):\n",
    "\n",
    "    found = False\n",
    "\n",
    "    while not found:\n",
    "\n",
    "        r_ann = random.choice(data_useful)\n",
    "\n",
    "        if r_ann['category_id'] in category_dict:\n",
    "\n",
    "            if category_dict[r_ann['category_id']] == category:\n",
    "\n",
    "                return r_ann\n",
    "\n",
    "\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86ee5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for category_name in ['person', 'vehicle', 'animal']:\n",
    "\n",
    "\n",
    "    total_created = 0\n",
    "\n",
    "    while total_created < num_samples_per_class:\n",
    "\n",
    "        ann = get_random_category_object(category_name, data_useful)\n",
    "\n",
    "        image = cv2.imread(DATA_DIR + 'val2017/%012d.jpg' % ann['image_id'])\n",
    "\n",
    "        h,w = image.shape[:2]\n",
    "\n",
    "        mask = annToMask(ann,\n",
    "            h,\n",
    "            w,)\n",
    "            \n",
    "        \n",
    "        # LOAD RANDOM BACKGROUND IMAGE\n",
    "        random_background_image ,background_image_shape = load_random_background_image()\n",
    "\n",
    "\n",
    "        # APPLY TRANSFORM TO SEGMENTATION OBJECT\n",
    "        image_new , mask_new = transform_object_and_mask(image.copy(),\n",
    "                                                        mask.copy(),)\n",
    "\n",
    "        # GET TRANSFORMED OBJECT PATH AND POSITIONS\n",
    "        patch, y, x, maximum_possible_y, maximum_possible_x = get_transformed_object_patch(image_new, \n",
    "                                                                                mask_new,\n",
    "                                                                                background_image_shape)\n",
    "\n",
    "        if (x.max()-x.min()) < 150 or (y.max()-y.min())<150:\n",
    "            continue\n",
    "\n",
    "        if (maximum_possible_x <= 30) or (maximum_possible_y <= 30):\n",
    "            continue\n",
    "\n",
    "        # PLACE TRANSFORMED OBJECT TO BACKGROUND IMAGE\n",
    "        place_transformed_object_patch(random_background_image,\n",
    "                                        patch,\n",
    "                                        y,\n",
    "                                        x,\n",
    "                                        maximum_possible_y,\n",
    "                                        maximum_possible_x,)\n",
    "\n",
    "\n",
    "        k = apply_augmentation(random_background_image[:,:,::-1])\n",
    "      \n",
    "        cv2.imwrite('./sentetik_data/%s_%08d.jpg' % (category_name, total_created), k[:,:,::-1] )\n",
    "\n",
    "        total_created += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
