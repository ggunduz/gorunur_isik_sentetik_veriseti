{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13462f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "DATA_DIR = './data/'\n",
    "\n",
    "NUM_TRAIN_SAMPLES = 40000\n",
    "NUM_VAL_SAMPLES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ba371f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mask_utils import *\n",
    "from utils.visualization_utils import *\n",
    "from utils.transform_utils import *\n",
    "from utils.data_utils import * \n",
    "from utils.augmentation_utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31e6132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open (DATA_DIR + './annotations_trainval2017/annotations/instances_train2017.json', \"r\")\n",
    "train_annotations = json.loads(f.read())\n",
    "\n",
    "\n",
    "f = open (DATA_DIR + './annotations_trainval2017/annotations/instances_val2017.json', \"r\")\n",
    "val_annotations = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bd81066",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = {1 : 'person',\n",
    "                 3 : 'vehicle',\n",
    "                 4 : 'vehicle',\n",
    "                 6 : 'vehicle',\n",
    "                 8 : 'vehicle',\n",
    "                 18 : 'animal',\n",
    "                 19 : 'animal',\n",
    "                 20 : 'animal',\n",
    "                 21 : 'animal',\n",
    "                 23 : 'animal',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3063e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Train: ', 362144, 'Val: ', 15310]\n",
      "['Train: ', 497857, 'Val: ', 21471]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "train_data_useful =[]\n",
    "train_data_background =[]\n",
    "\n",
    "for ann in train_annotations['annotations']:\n",
    "    \n",
    "    if ann['category_id'] in category_dict:\n",
    "        train_data_useful.append(ann)\n",
    "\n",
    "    else:\n",
    "        train_data_background.append(ann)\n",
    "\n",
    "\n",
    "val_data_useful =[]\n",
    "val_data_background =[]\n",
    "\n",
    "for ann in val_annotations['annotations']:\n",
    "    \n",
    "    if ann['category_id'] in category_dict:\n",
    "        val_data_useful.append(ann)\n",
    "\n",
    "    else:\n",
    "        val_data_background.append(ann)\n",
    "\n",
    "print(['Train: ' ,len(train_data_useful), \n",
    "       'Val: ', len(val_data_useful)])\n",
    "\n",
    "print(['Train: ' ,len(train_data_background), \n",
    "       'Val: ', len(val_data_background)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "334d4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_category_object(category,\n",
    "                             data_useful):\n",
    "\n",
    "    found = False\n",
    "\n",
    "    while not found:\n",
    "\n",
    "        r_ann = random.choice(data_useful)\n",
    "\n",
    "        if r_ann['category_id'] in category_dict:\n",
    "\n",
    "            if category_dict[r_ann['category_id']] == category:\n",
    "\n",
    "                return r_ann    \n",
    "\n",
    "def get_random_background_object(data_background):\n",
    "\n",
    "    return random.choice(data_background)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b86ee5d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30843/54040105.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m# APPLY TRANSFORM TO SEGMENTATION OBJECT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 image_new , mask_new = transform_object_and_mask(image.copy(),\n\u001b[0;32m---> 48\u001b[0;31m                                                                 mask.copy(),)\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# GET TRANSFORMED OBJECT PATH AND POSITIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/sekiza/gorunur_isik_sentetik_veriseti/utils/transform_utils.py\u001b[0m in \u001b[0;36mtransform_object_and_mask\u001b[0;34m(image, mask, rotation)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mrotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/scipy/ndimage/interpolation.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(input, angle, axes, reshape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0moa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             affine_transform(ia, rot_matrix, offset, out_plane_shape,\n\u001b[0;32m--> 956\u001b[0;31m                              oa, order, mode, cval, prefilter)\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/scipy/ndimage/interpolation.py\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    611\u001b[0m         _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n\u001b[1;32m    612\u001b[0m                                       \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m                                       None)\n\u001b[0m\u001b[1;32m    614\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "for split, num_samples_per_class, data_useful in [('train', NUM_TRAIN_SAMPLES, train_data_useful),\n",
    "                                     ('val', NUM_VAL_SAMPLES, val_data_useful)]:\n",
    "\n",
    "    for category_name in ['person', 'vehicle', 'animal']:\n",
    "\n",
    "\n",
    "        total_created = 0\n",
    "        directory = './sentetik_data/%s/%s/' % (split, category_name)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "        np.random.seed(SEED)\n",
    "        rn.seed(SEED)\n",
    "\n",
    "        while total_created < num_samples_per_class:\n",
    "        \n",
    "\n",
    "            \n",
    "            # LOAD RANDOM BACKGROUND IMAGE\n",
    "            random_background_image ,background_image_shape = load_random_background_image()\n",
    "\n",
    "            cur_added = 0 \n",
    "            while cur_added < 1:\n",
    "\n",
    "                \n",
    "                SEED += 1\n",
    "                ann = get_random_category_object(category_name, data_useful)\n",
    "\n",
    "                image = cv2.imread(DATA_DIR + f\"{split}2017/{split}2017/%012d.jpg\" % (ann['image_id']))\n",
    "\n",
    "                h,w = image.shape[:2]\n",
    "\n",
    "                mask = annToMask(ann,\n",
    "                    h,\n",
    "                    w,)\n",
    "                \n",
    "\n",
    "\n",
    "                # APPLY TRANSFORM TO SEGMENTATION OBJECT\n",
    "                image_new , mask_new = transform_object_and_mask(image.copy(),\n",
    "                                                                mask.copy(),)\n",
    "\n",
    "                # GET TRANSFORMED OBJECT PATH AND POSITIONS\n",
    "                try:\n",
    "                    patch, y, x, maximum_possible_y, maximum_possible_x = get_transformed_object_patch(image_new, \n",
    "                                                                                            mask_new,\n",
    "                                                                                            background_image_shape)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if (x.max()-x.min()) < 40 or (y.max()-y.min())<40:\n",
    "                    continue\n",
    "\n",
    "                if (maximum_possible_x <= 30) or (maximum_possible_y <= 30):\n",
    "                    continue\n",
    "\n",
    "                # PLACE TRANSFORMED OBJECT TO BACKGROUND IMAGE\n",
    "                place_transformed_object_patch(random_background_image,\n",
    "                                                patch,\n",
    "                                                y,\n",
    "                                                x,\n",
    "                                                maximum_possible_y,\n",
    "                                                maximum_possible_x,)\n",
    "\n",
    "                cur_added += 1\n",
    "\n",
    "            k = apply_augmentation(random_background_image[:,:,::-1])\n",
    "        \n",
    "            cv2.imwrite(directory+ '/%s_%08d.jpg' % (category_name, total_created), k[:,:,::-1] )\n",
    "\n",
    "            total_created += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e83f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "for split, num_samples_per_class, data_useful in [('train', NUM_TRAIN_SAMPLES, train_data_background),\n",
    "                                     ('val', NUM_VAL_SAMPLES, val_data_background)]:\n",
    "\n",
    "    for category_name in ['background']:\n",
    "\n",
    "\n",
    "        total_created = 0\n",
    "\n",
    "        directory = './sentetik_data/%s/%s/' % (split, category_name)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "        np.random.seed(SEED)\n",
    "        rn.seed(SEED)\n",
    "\n",
    "        while total_created < num_samples_per_class:\n",
    "\n",
    "\n",
    "            # LOAD RANDOM BACKGROUND IMAGE\n",
    "            random_background_image ,background_image_shape = load_random_background_image()\n",
    "\n",
    "            cur_added = 0 \n",
    "            while cur_added < 1:\n",
    "                SEED += 1\n",
    "\n",
    "                ann = get_random_background_object(data_useful)\n",
    "\n",
    "                image = cv2.imread(DATA_DIR + f\"{split}2017/{split}2017/%012d.jpg\" % (ann['image_id']))\n",
    "\n",
    "                h,w = image.shape[:2]\n",
    "\n",
    "                mask = annToMask(ann,\n",
    "                    h,\n",
    "                    w,)\n",
    "                \n",
    "\n",
    "\n",
    "                # APPLY TRANSFORM TO SEGMENTATION OBJECT\n",
    "                image_new , mask_new = transform_object_and_mask(image.copy(),\n",
    "                                                                mask.copy(),)\n",
    "\n",
    "                # GET TRANSFORMED OBJECT PATH AND POSITIONS\n",
    "                try:\n",
    "                    patch, y, x, maximum_possible_y, maximum_possible_x = get_transformed_object_patch(image_new, \n",
    "                                                                                            mask_new,\n",
    "                                                                                            background_image_shape)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if (x.max()-x.min()) < 40 or (y.max()-y.min())<40:\n",
    "                    continue\n",
    "\n",
    "                if (maximum_possible_x <= 30) or (maximum_possible_y <= 30):\n",
    "                    continue\n",
    "\n",
    "                # PLACE TRANSFORMED OBJECT TO BACKGROUND IMAGE\n",
    "                place_transformed_object_patch(random_background_image,\n",
    "                                                patch,\n",
    "                                                y,\n",
    "                                                x,\n",
    "                                                maximum_possible_y,\n",
    "                                                maximum_possible_x,)\n",
    "\n",
    "                cur_added += 1\n",
    "\n",
    "            k = apply_augmentation(random_background_image[:,:,::-1])\n",
    "        \n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "\n",
    "            cv2.imwrite(directory+ '/%s_%08d.jpg' % (category_name, total_created), k[:,:,::-1] )\n",
    "\n",
    "            total_created += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
